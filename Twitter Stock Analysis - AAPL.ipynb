{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckey = \"DnAPBR25Wo9g2mAbbQe7jNnJf\"\n",
    "csecret = \"XBSR3bwR9Eadk1ykDb9ScKZKvm5p2CDjf69mYnsR8RuBTHIiYh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoken = \"1179559654700941312-UUh5kKPHp8sA5e6YYFwl7NpBNzz7C3\"\n",
    "asecret = \"4JeWZ2lIMcH0rvbD5eWsWmwVnmgcdh4b8phaUcQ3LAC9K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('twitter_AAPL.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = conn.cursor()\n",
    "\n",
    "def create_table():\n",
    "    c.execute(\"CREATE TABLE IF NOT EXISTS sentiment(unix REAL, tweet TEXT, sentiment REAL)\")\n",
    "    conn.commit()\n",
    "\n",
    "create_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "loaded_model = load_model('GRU_all_vocab_model.h5')\n",
    "\n",
    "def sentiment(tweet):\n",
    "    word_token = word_tokenize(tweet)\n",
    "    target_text = []\n",
    "    for word in word_token:\n",
    "        # 단어를 소문자로 변환 => 만약에 영화리뷰 감정 분석에 쓰였던 단어면 포함\n",
    "        # 아니면 제외\n",
    "        if word.lower() in word_to_index:\n",
    "            # 단어를 word_to_index에서 찾아서, 숫자로 변환 \n",
    "#             if word_to_index[word.lower()] < 10000:\n",
    "                target_text.append(word_to_index[word.lower()])\n",
    "    if len(target_text) == 0:\n",
    "        return None # 분석할 단어가 없어서 감정 분석 불가능\n",
    "    \n",
    "    print(len(target_text))\n",
    "    x_text = np.array([target_text])\n",
    "    \n",
    "    max_len = 500\n",
    "    X_train = pad_sequences(x_text, maxlen = max_len)\n",
    "    \n",
    "    try:\n",
    "        predicted = loaded_model.predict(X_train)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x14175d2d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"DELETE FROM sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[0.39061442]]\n",
      "8\n",
      "[[2.6056246e-05]]\n",
      "14\n",
      "[[0.9867359]]\n",
      "10\n",
      "[[0.04674029]]\n",
      "12\n",
      "[[0.00398606]]\n",
      "18\n",
      "[[0.4907135]]\n",
      "22\n",
      "[[0.9521588]]\n",
      "10\n",
      "[[0.09600449]]\n",
      "10\n",
      "[[0.88255835]]\n",
      "16\n",
      "[[6.361341e-05]]\n",
      "12\n",
      "[[0.06565759]]\n",
      "None\n",
      "3\n",
      "[[0.816676]]\n",
      "11\n",
      "[[0.00062999]]\n",
      "16\n",
      "[[0.00068885]]\n",
      "17\n",
      "[[0.00153407]]\n",
      "11\n",
      "[[0.99874145]]\n",
      "7\n",
      "[[0.48797554]]\n",
      "4\n",
      "[[0.00011518]]\n",
      "5\n",
      "[[7.074033e-05]]\n",
      "21\n",
      "[[0.99870634]]\n",
      "18\n",
      "[[0.19841924]]\n",
      "20\n",
      "[[0.00710285]]\n",
      "22\n",
      "[[0.00098839]]\n",
      "19\n",
      "[[0.8960464]]\n",
      "19\n",
      "[[0.99163294]]\n",
      "22\n",
      "[[4.0863792e-06]]\n",
      "14\n",
      "[[0.0001119]]\n",
      "11\n",
      "[[0.00603655]]\n",
      "18\n",
      "[[0.9891906]]\n",
      "12\n",
      "[[0.00398606]]\n",
      "13\n",
      "[[0.0011678]]\n",
      "11\n",
      "[[0.00062999]]\n",
      "11\n",
      "[[0.00062999]]\n",
      "13\n",
      "[[0.00205901]]\n",
      "11\n",
      "[[0.01258591]]\n",
      "11\n",
      "[[0.00062999]]\n",
      "11\n",
      "[[0.01258591]]\n",
      "9\n",
      "[[0.00370309]]\n",
      "23\n",
      "[[0.07347062]]\n",
      "8\n",
      "[[0.02590802]]\n",
      "24\n",
      "[[0.00426859]]\n",
      "12\n",
      "[[0.05278149]]\n",
      "1\n",
      "[[0.69687325]]\n",
      "1\n",
      "[[0.69687325]]\n",
      "13\n",
      "[[0.0011678]]\n",
      "18\n",
      "[[0.9584085]]\n",
      "20\n",
      "[[0.9109911]]\n",
      "1\n",
      "[[0.69687325]]\n",
      "1\n",
      "[[0.69687325]]\n",
      "1\n",
      "[[0.69687325]]\n",
      "13\n",
      "[[0.0011678]]\n",
      "None\n",
      "1\n",
      "[[0.69687325]]\n",
      "16\n",
      "[[0.3242784]]\n",
      "11\n",
      "[[0.00062999]]\n",
      "8\n",
      "[[0.00416127]]\n",
      "1\n",
      "[[0.69687325]]\n",
      "8\n",
      "[[0.13141182]]\n",
      "None\n",
      "4\n",
      "[[0.4184537]]\n",
      "21\n",
      "[[0.00025994]]\n",
      "11\n",
      "[[0.01258591]]\n",
      "15\n",
      "[[0.95275164]]\n",
      "11\n",
      "[[0.00265974]]\n",
      "12\n",
      "[[0.00653055]]\n",
      "9\n",
      "[[0.71713]]\n",
      "18\n",
      "[[0.76507926]]\n",
      "9\n",
      "[[0.00370309]]\n",
      "12\n",
      "[[0.09656948]]\n",
      "5\n",
      "[[0.00372401]]\n",
      "21\n",
      "[[0.19610015]]\n",
      "22\n",
      "[[0.04500329]]\n",
      "1\n",
      "[[0.69687325]]\n",
      "12\n",
      "[[0.00021094]]\n",
      "15\n",
      "[[0.07858837]]\n",
      "10\n",
      "[[0.82132304]]\n",
      "15\n",
      "[[0.00650263]]\n",
      "10\n",
      "[[0.54938287]]\n",
      "13\n",
      "[[0.0011678]]\n",
      "15\n",
      "[[0.0001104]]\n",
      "22\n",
      "[[0.9808086]]\n",
      "16\n",
      "[[0.00068885]]\n",
      "12\n",
      "[[0.00398606]]\n",
      "13\n",
      "[[0.99798775]]\n",
      "17\n",
      "[[0.00311911]]\n",
      "19\n",
      "[[0.01578149]]\n",
      "3\n",
      "[[0.9986992]]\n",
      "2\n",
      "[[0.00409645]]\n",
      "12\n",
      "[[0.00398606]]\n",
      "13\n",
      "[[0.00205901]]\n",
      "10\n",
      "[[0.00047579]]\n",
      "10\n",
      "[[0.00047579]]\n",
      "3\n",
      "[[0.39061442]]\n",
      "12\n",
      "[[0.00647959]]\n",
      "4\n",
      "[[0.141758]]\n",
      "2\n",
      "[[0.34687582]]\n",
      "None\n",
      "13\n",
      "[[0.0011678]]\n",
      "17\n",
      "[[0.00069791]]\n",
      "11\n",
      "[[0.01258591]]\n",
      "13\n",
      "[[0.0011678]]\n",
      "11\n",
      "[[0.06740338]]\n",
      "14\n",
      "[[9.969261e-05]]\n"
     ]
    }
   ],
   "source": [
    "class listener(StreamListener):\n",
    "    def on_data(self, data):\n",
    "        # twitter에서 업데이트 된 twit이 data로 저장.\n",
    "        # 업데이트 된 twit의 text가 긍정인지, 부정인지를 판단\n",
    "        # 각 twit이 긍정이었는지, 부정이었는지 저장. \n",
    "        # 위 데이터가 시간대별로 쌓이면 => 어떤 주식 sentiment가 어떻게 변했는지 그리고 어떻게 변화하고 있는지.\n",
    "        # json\n",
    "        all_data = json.loads(data)\n",
    "        \n",
    "        tweet = all_data[\"text\"]\n",
    "        sentiment_value = sentiment(tweet)\n",
    "        print(sentiment_value)\n",
    "        if sentiment_value != None:\n",
    "            time_ms = all_data['timestamp_ms']\n",
    "            c.execute(\"INSERT INTO sentiment (unix, tweet, sentiment) VALUES (?,?,?)\", (time_ms, tweet, float(sentiment_value[0][0])))\n",
    "            conn.commit()\n",
    "            output = open(\"twitter-AAPL.txt\", \"a\")\n",
    "            output.write(str(sentiment_value[0][0]))\n",
    "            output.write('\\n')\n",
    "            output.close()\n",
    "        return True\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "auth = OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken, asecret)\n",
    "\n",
    "twitter_stream = Stream(auth, listener())\n",
    "twitter_stream.filter(track=[\"AAPL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
