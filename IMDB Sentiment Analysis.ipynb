{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰데이터 \n",
    "# IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(word_to_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {}\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value+3] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> please give this one a miss br br kristy swanson and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite lacklustre so all you madison fans give this a miss\n"
     ]
    }
   ],
   "source": [
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index] = token\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     1,    14,    22,    16,    43,   530,\n",
       "         973,  1622,  1385,    65,   458,  4468,    66,  3941,     4,\n",
       "         173,    36,   256,     5,    25,   100,    43,   838,   112,\n",
       "          50,   670, 22665,     9,    35,   480,   284,     5,   150,\n",
       "           4,   172,   112,   167, 21631,   336,   385,    39,     4,\n",
       "         172,  4536,  1111,    17,   546,    38,    13,   447,     4,\n",
       "         192,    50,    16,     6,   147,  2025,    19,    14,    22,\n",
       "           4,  1920,  4613,   469,     4,    22,    71,    87,    12,\n",
       "          16,    43,   530,    38,    76,    15,    13,  1247,     4,\n",
       "          22,    17,   515,    17,    12,    16,   626,    18, 19193,\n",
       "           5,    62,   386,    12,     8,   316,     8,   106,     5,\n",
       "           4,  2223,  5244,    16,   480,    66,  3785,    33,     4,\n",
       "         130,    12,    16,    38,   619,     5,    25,   124,    51,\n",
       "          36,   135,    48,    25,  1415,    33,     6,    22,    12,\n",
       "         215,    28,    77,    52,     5,    14,   407,    16,    82,\n",
       "       10311,     8,     4,   107,   117,  5952,    15,   256,     4,\n",
       "       31050,     7,  3766,     5,   723,    36,    71,    43,   530,\n",
       "         476,    26,   400,   317,    46,     7,     4, 12118,  1029,\n",
       "          13,   104,    88,     4,   381,    15,   297,    98,    32,\n",
       "        2071,    56,    26,   141,     6,   194,  7486,    18,     4,\n",
       "         226,    22,    21,   134,   476,    26,   480,     5,   144,\n",
       "          30,  5535,    18,    51,    36,    28,   224,    92,    25,\n",
       "         104,     4,   226,    65,    16,    38,  1334,    88,    12,\n",
       "          16,   283,     5,    16,  4472,   113,   103,    32,    15,\n",
       "          16,  5345,    19,   178,    32], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 88587\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(GRU(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint('GRU_all_vocab_model.h5', monitor = 'val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "334/334 [==============================] - 314s 928ms/step - loss: 0.6235 - acc: 0.6317 - val_loss: 0.4427 - val_acc: 0.8014\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.80140, saving model to GRU_all_vocab_model.h5\n",
      "Epoch 2/15\n",
      "334/334 [==============================] - 293s 878ms/step - loss: 0.2502 - acc: 0.9038 - val_loss: 0.3240 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.80140 to 0.86680, saving model to GRU_all_vocab_model.h5\n",
      "Epoch 3/15\n",
      "334/334 [==============================] - 304s 911ms/step - loss: 0.1006 - acc: 0.9646 - val_loss: 0.3807 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.86680 to 0.87260, saving model to GRU_all_vocab_model.h5\n",
      "Epoch 4/15\n",
      "334/334 [==============================] - 325s 973ms/step - loss: 0.0361 - acc: 0.9902 - val_loss: 0.4551 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.87260 to 0.87420, saving model to GRU_all_vocab_model.h5\n",
      "Epoch 5/15\n",
      "334/334 [==============================] - 315s 944ms/step - loss: 0.0196 - acc: 0.9938 - val_loss: 0.5798 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.87420\n",
      "Epoch 6/15\n",
      "334/334 [==============================] - 264s 790ms/step - loss: 0.0218 - acc: 0.9936 - val_loss: 0.5125 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87420\n",
      "Epoch 7/15\n",
      "334/334 [==============================] - 239s 717ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.6498 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.87420 to 0.87460, saving model to GRU_all_vocab_model.h5\n",
      "Epoch 8/15\n",
      "334/334 [==============================] - 254s 760ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.6990 - val_acc: 0.8698\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.87460\n",
      "Epoch 9/15\n",
      "334/334 [==============================] - 277s 828ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.6572 - val_acc: 0.8758\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.87460 to 0.87580, saving model to GRU_all_vocab_model.h5\n",
      "Epoch 10/15\n",
      "334/334 [==============================] - 260s 777ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.6895 - val_acc: 0.8478\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.87580\n",
      "Epoch 11/15\n",
      "334/334 [==============================] - 279s 834ms/step - loss: 0.0044 - acc: 0.9984 - val_loss: 0.7065 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.87580\n",
      "Epoch 12/15\n",
      "334/334 [==============================] - 251s 750ms/step - loss: 0.0059 - acc: 0.9975 - val_loss: 0.7267 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.87580\n",
      "Epoch 13/15\n",
      "334/334 [==============================] - 236s 706ms/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.7631 - val_acc: 0.8504\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.87580\n",
      "Epoch 14/15\n",
      "334/334 [==============================] - 232s 694ms/step - loss: 0.0091 - acc: 0.9970 - val_loss: 0.6738 - val_acc: 0.8608\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.87580\n",
      "Epoch 15/15\n",
      "334/334 [==============================] - 269s 805ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.7609 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.87580\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=15, batch_size=60, callbacks=[mc], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('GRU_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 96s 122ms/step - loss: 0.3421 - acc: 0.8709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3420592248439789, 0.8708800077438354]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48800018],\n",
       "       [0.99526024],\n",
       "       [0.8498404 ],\n",
       "       ...,\n",
       "       [0.06781477],\n",
       "       [0.27119994],\n",
       "       [0.5155628 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
